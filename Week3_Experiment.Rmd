---
title: "What is a Text? Experiments"
output: html_notebook
---

## Objective and Output

Code: You will try out the exercises and code in the chapter and then adapt it to fit a text of your interest.

Notebook: As you work you can keep track of your success (and failure) in an R markdown notebook. Share it through this discussion thread, either as an html output or as the original Rmd file.

## Foundations

Complete chapters 1 and 3 of Text Mining with R: A Tidy Approach: https://www.tidytextmining.com/ (Links to an external site.)Links to an external site.
Using these same methods, and then try to apply them to a different set of texts.

### Chapter 1: The tidy text format

#### 1.1 Contrasting tidy text with other data structures

##### Definitions
one-token-per-row
string
corpus
document-term matrix

#### 1.2 The unnest_tokens function

```{r}
text <- c("Because I could not stop for Death -",
          "He kindly stopped for me -",
          "The Carriage held but just Ourselves -",
          "and Immortality")
text
```

Notes:
(Terminology) Character vector > tidy text dataset
(Shortcut): Ctrl + Alt + I to create new code chunk

```{r}
library(dplyr)
text_df <- data_frame(line = 1:4, text = text)

text_df
```

Notes: 

If library doesnt't run, Click Tools > Install Packages and type in the name of the library/package

When installing packages, running any code will not work (also additional browsers in the background may cause the program to install slower than expected)

All installed packages should appear in the right bottom window of R Studio

The dataframe appears differently from the textbook example. The right box, when clicked, shows the list as a 4x2 data table

```{r}
library(tidytext)

text_df %>%
  unnest_tokens(word, text)
```

To run all of the code, use the green arrow in the corner. To run the line that the cursor is on: Ctrl + Enter

If a line is run without the needed library, you will get an error. Re-run line that calls the required library

#### 1.3 Tidying the works of Jane Austen

```{r}
library(janeaustenr)
library(dplyr)
library(stringr)

original_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                                                 ignore_case = TRUE)))) %>%
  ungroup()

original_books
```

Use black arrow for more columns. Readability is limited in Terminal view, however, I'm assuming that the view is better in the html version of the R notebook. 

```{r}
library(tidytext)
tidy_books <- original_books %>%
  unnest_tokens(word, text)

tidy_books
```

The code below removes stop_words from tidy_books. stop_words is already a pre-selected collection of words
```{r}
# incorrect code: stopwords // this outputs an error

data(stop_words)

tidy_books <- tidy_books %>%
  anti_join(stop_words)
```

Things like stop_words may already be defined. If you are curious about specifically what set you are using, it is easy to look up the content of the object. Example

```{r}
stop_words
```

This is the resulting tidy_books since we made changes to the same variable 

```{r}
tidy_books
```

At this point, I've realized that the code, although helpful to see notes above and below, still need to be commented for better documentation of the process. Just a note to self

```{r}
tidy_books %>%
  count(word, sort = TRUE) 
```

This tidbit of code counts the frequency of the "words" in tidy_books and sorts the results by number of frequency

Now numbers are great, but its easier to compare data when given a visual comparison 

```{r}
library(ggplot2)

tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

This code is a little more complicated, but the end goal is to show the most common words in the Jane Austen package. 

Note: Look up the use of each function within the previous code chunk

#### 1.4 The gutenberg package

https://github.com/ropensci/gutenbergr

#### 1.5 Word Frequencies

Upload certain texts into hgwells, multiple books. Specifically picked using their IDs
```{r}
library(gutenbergr)

hgwells <- gutenberg_download(c(35, 36, 5230, 159))
```
I printed out the variable to see exactly what the download function did
```{r}
hgwells 
```

Based on the columns, I can only assume that each number in the download corresponds to The Time Machine, The War of the Worlds, The Invisible Man, and The Island of Doctor Moreau, respectively. Since there are only 2 columns, the contents of each book are just stacked upon each other. 

```{r}
tidy_hgwells <- hgwells %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```
^ remove stop_words and separate texts into words (individually in the column)
```{r}
#sort words in tidy_hgwells by descending order
tidy_hgwells %>%
  count(word, sort = TRUE)
```
Note: look up the arguments of count() : are there more besides sort

```{r}
# works of the bronte sisters 
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))
```
No need to print bronte since it will be a similar layout to hgwells

```{r}
# upload all words in bronte except for the stop_words
tidy_bronte <- bronte %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```
Again, following the same format as hgwells

```{r}
# sort remaining words by the most frequent 
tidy_bronte %>%
  count(word, sort = TRUE)
```
You might've noticed, I've started adding comments within the code. If it's one line and a description of the code, gets thrown within the code. Otherwise, longer or irrelevant descriptions can be written in markdown (outside of code chunks).

```{r}
library(tidyr)
# calculate the frequency for each word for the works of Jane Austen, the Brontë sisters, and H.G. Wells
frequency <- bind_rows(mutate(tidy_bronte, author = "Brontë Sisters"),
                       mutate(tidy_hgwells, author = "H.G. Wells"), 
                       mutate(tidy_books, author = "Jane Austen")) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%
  count(author, word) %>%
  group_by(author) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(author, proportion) %>% 
  gather(author, proportion, `Brontë Sisters`:`H.G. Wells`)
```
Lots of functions that we don't know about:
str_extract - for an equal comparison of _any_ (italics) and any
spread, gather - for reshaping the dataframes

```{r}
library(scales)

# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Jane Austen", x = NULL)
```
^ this plots the alignment in word frequency for Jane austen vs hgwells and Jane Austen vs bronte

```{r}
cor.test(data = frequency[frequency$author == "Brontë Sisters",],
         ~ proportion + `Jane Austen`)
```
^ if visual graphics aren't your thing, here's some numbers to give you a better idea of how similar the word frequency is between Bronte and Jane Austen

```{r}
cor.test(data = frequency[frequency$author == "H.G. Wells",], 
         ~ proportion + `Jane Austen`)
```

^ if visual graphics aren't your thing, here's some numbers to give you a better idea of how similar the word frequency is between HG Wells and Jane Austen

The word frequencies are more correlated between the Austen and Brontë novels than between Austen and H.G. Wells.

### Chapter 3: Analyzing word and document frequency: tf-idf

#### 3.1 Term Frequency in Jane Austen's novels 

What are the most commonly used words in Jane Austen’s novels? (Let’s also calculate the total words in each novel here, for later use.)

```{r}
book_words <- austen_books() %>%
  unnest_tokens(word, text) %>%
  count(book, word, sort = TRUE) %>%
  ungroup()

total_words <- book_words %>% 
  group_by(book) %>% 
  summarize(total = sum(n))

book_words <- left_join(book_words, total_words)

book_words
```

n is the number of times that word is used in that book and total is the total words in that book. The usual suspects are here with the highest n, “the”, “and”, “to”, and so forth.

```{r}
ggplot(book_words, aes(n/total, fill = book)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~book, ncol = 2, scales = "free_y")
```

This is a more visual representation of the word frequency per each Austen novel

#### 3.2 Zipf's Law

Zipf's Law: the relationship between the frequency that a word is used and its rank are inversely proportional

```{r}
freq_by_rank <- book_words %>% 
  group_by(book) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

freq_by_rank
```
calculating the rank number based on the original row number of book_words (jane austen works) to further calculate frequency by rank while considering the frequecy within each book by dividing by the total number of words in each book

```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = book)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

As visually seen by the negative slope, Zipf's law is proven true. Below is more confirmation that the slope is negative.

```{r}
rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```
Below is the same plot with a fitted line with the same coeff as stated above
```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = book)) + 
  geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

#### 3.3. The bind_tf_idf function

```{r}
book_words <- book_words %>%
  bind_tf_idf(word, book, n)
book_words
```
^ This simplifies the process immensely that we have been working through both chapters
```{r}
book_words %>%
  select(-total) %>%
  arrange(desc(tf_idf))
```
^ this removes the total column (as it is the same for all words) and arranges the tf_idf in descending order (assumingly for the purposes of tf and idf are inversely proportional)

```{r}
book_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(book) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = book)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~book, ncol = 2, scales = "free") +
  coord_flip()
```
^ plot of each of the texts and the words with the highest tf_idf 

#### 3.4 A corpus of physics texts

```{r}
physics <- gutenberg_download(c(37729, 14725, 13476, 5001), 
                              meta_fields = "author")
```

ah new argument! meta_fields within gutenberg_download()
```{r}
physics_words <- physics %>%
  unnest_tokens(word, text) %>%
  count(author, word, sort = TRUE) %>%
  ungroup()

physics_words
```
counted words organized by author and then organized in descending order n

```{r}
plot_physics <- physics_words %>%
  bind_tf_idf(word, author, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  mutate(author = factor(author, levels = c("Galilei, Galileo",
                                            "Huygens, Christiaan", 
                                            "Tesla, Nikola",
                                            "Einstein, Albert")))

plot_physics %>% 
  group_by(author) %>% 
  top_n(15, tf_idf) %>% 
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = author)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~author, ncol = 2, scales = "free") +
  coord_flip()
```
plot of the different authors and the words with the highest tf-idf 
```{r}
physics %>% 
  filter(str_detect(text, "eq\\.")) %>% 
  select(text)
```
you can use filter to view the lines with a specific string (word or phrase). This is done a couple of times to be critical of the automatic processes in this program. 

```{r}
physics %>% 
  filter(str_detect(text, "K1")) %>% 
  select(text)
```


```{r}
physics %>% 
  filter(str_detect(text, "AK")) %>% 
  select(text)
```
Since eq isn't a frequent word, more like akin to a caption label for equations, and there are more words that lack importance within the content, let's customize new stop words and then plot them again.

```{r}
mystopwords <- data_frame(word = c("eq", "co", "rc", "ac", "ak", "bn", 
                                   "fig", "file", "cg", "cb", "cm"))
physics_words <- anti_join(physics_words, mystopwords, by = "word")
plot_physics <- physics_words %>%
  bind_tf_idf(word, author, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(author) %>% 
  top_n(15, tf_idf) %>%
  ungroup %>%
  mutate(author = factor(author, levels = c("Galilei, Galileo",
                                            "Huygens, Christiaan",
                                            "Tesla, Nikola",
                                            "Einstein, Albert")))

ggplot(plot_physics, aes(word, tf_idf, fill = author)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~author, ncol = 2, scales = "free") +
  coord_flip()
```

### Trying it on my own texts


Initially I thought to do some exploring through code since it seemed more efficient than searching through the meta-data myself

```{r}
gutenberg_metadata
```

I still haven't gotten use to calling the functions in R so I looked through the variable  and clicked on it within the top right corner of R Studio and looked through that way. I'll list the steps down so that I can come back and see if I can replicate this in code.

1. Search for Lewis Carroll texts, find author ID (7)
2. Search for Frank L. Baum texts, find author ID (42)
3. Search for A. A. Milne texts, find author ID (730)
```{r}
# I was hoping this line just downloaded the texts corresponding to the specific author IDs
myTexts <- gutenberg_download(c(7, 42, 730), 
                              meta_fields = "author")
myTexts
#i was wrong
```

```{r}
gutenberg_metadata %>% filter(author == "Carroll, Lewis")
```

