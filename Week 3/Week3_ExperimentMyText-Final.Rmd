---
title: "Gutenberg Corpus"
output: html_notebook
---

A clean start to get my corpus up and running.

```{r}
# This is to group all libraries for import (a style found in most programming languages)
library(gutenbergr)
library(dplyr)
library(tidytext)
library(tidyr)
library(stringr)
library(scales)
library(ggplot2)
```

```{r}
# this filters out from gutenberg_metadata ( )
gutenberg_metadata %>% filter(author == "Carroll, Lewis", str_detect(gutenberg_bookshelf, "Children's Literature"), language == "en",  has_text, !str_detect(title, "facsimile")) %>% distinct(title)
```

Note to self: gutenberg_download(meta_fields = "title", "author") will not run. gutenberg_download(meta_fields = c("title", "author")) will run. 
 
```{r}
carroll <- gutenberg_works(author == "Carroll, Lewis", str_detect(gutenberg_bookshelf, "Children's Literature"), !str_detect(title, "facsimile")) %>%
  gutenberg_download(meta_fields = c("title", "author"))
```

carroll contains actual text of the 3 books that I want from Lewis Carroll - Alice in Wonderland, Through the Looking Glass, and The Hunting of the Snark: An Agony in Eight Fits. These are all childrens literature and not an analysis of texts (which Is why I decided to exclude the "facsimile" piece bt Lewis Carroll) - the titles of the books in carroll are listed under lewis1 just to make sure I got the right books

```{r}
gutenberg_metadata %>% filter(author == "Baum, L. Frank (Lyman Frank)", str_detect(gutenberg_bookshelf, "Children's Literature"), language == "en",  has_text) %>% distinct(title)
```

```{r}
frank <- gutenberg_works(author == "Baum, L. Frank (Lyman Frank)", str_detect(gutenberg_bookshelf, "Children's Literature")) %>%
  gutenberg_download(meta_fields = c("title", "author"))
```

Could not download Little Wizard Stories of Oz (which is ok)

```{r}
gutenberg_metadata %>% filter(author == "Milne, A. A. (Alan Alexander)", str_detect(gutenberg_bookshelf, "Detective Fiction"), language == "en",  has_text) %>% distinct(title)
```

```{r}
alanalexander <- gutenberg_works(author == "Milne, A. A. (Alan Alexander)", str_detect(gutenberg_bookshelf, "Detective Fiction")) %>%
  gutenberg_download(meta_fields = c("title", "author"))
```

This only has one work: The Red House Mystery. I felt it as a nice addition to still include AA Milne even though Winnie The Pooh remains unavailable on gutenberg

```{r}
gutenberg_metadata %>% filter(author == "Doyle, Arthur Conan", str_detect(gutenberg_bookshelf, "Detective Fiction"), language == "en",  has_text) %>% distinct(title)
```

```{r}
arthur <- gutenberg_works(author == "Doyle, Arthur Conan", str_detect(gutenberg_bookshelf, "Detective Fiction")) %>%
  gutenberg_download(meta_fields = c("title", "author"))
```

Finally, 4 corpora that have only detective fiction and children's literature
Now to simplify them into 2 corpus (one of Children's Literature and the other of Detective Fiction)

```{r}
childrensLit <- bind_rows(carroll, frank)
detectiveFiction <- bind_rows(arthur, alanalexander)
```

```{r}
# to check and see if page numbers and chapter numbers would interfere with the word frequency count for childrens lit corpus (they will)

test <- childrensLit %>% filter(str_detect(text, regex("[0-9]"))) %>% select(text)
```
 I messed with the interior but basically it includes chapter headings and  
```{r}
# Adds the number of words in each str vector 
test$charcount = str_count(test$text, "\\S+")
```

```{r}
# all of the numbers (without chapter titles?)

# i found that the most amount of words for in text numbers is around 10 or more words 
dat1 <- filter(test, charcount < 10 && !str_detect(text, regex("chapter", ignore_case = )))
```

```{r}
# lets take out the numbers
childsLit_clean <- childrensLit[!childrensLit$text %in% dat1$text, , drop = FALSE]
```

```{r}
# seeing chapter names in the cleaned corpus
filter(childsLit_clean, str_detect(text, regex("^chapter ", ignore_case = TRUE)))
```


```{r}
# to check and see if page numbers and chapter numbers would interfere with the word frequency count for detective fiction corpus (they will not)
detectiveFiction %>% filter(str_detect(text, regex("[0-9]"))) %>% select(text)
```


```{r}
# This is to set chapter numbers next to the text
child_books <- childrensLit %>%
  group_by(title) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%   ungroup()
```

```{r}
detective_books <- detectiveFiction %>%
  group_by(title) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%   ungroup()
```

Some texts do not have a mention of chapters and should be adjusted accordingly

# Week 3

```{r}
# upload all words in detective corpus except for the stop_words
tidy_detective <- detective_books %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```

```{r}
# sort remaining words by the most frequent 
tidy_detective %>%
  count(word, sort = TRUE)
```

```{r}
# upload all words in childrens lit corpus except for the stop_words
tidy_childrensLit <- child_books %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```

```{r}
# sort remaining words by the most frequent 
tidy_childrensLit %>%
  count(word, sort = TRUE)
```

```{r}
# calculates frequency and combines detective and childrens copus into one variable
frequency_dc <- bind_rows(mutate(tidy_detective, corpus = "Detective"), mutate(tidy_childrensLit, corpus = "Children's Literature")) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%
  count(corpus, word) %>%
  group_by(corpus) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(corpus, proportion) %>% 
  gather(corpus, proportion, `Detective`)
```

This Data Wrangling Cheat Sheet helped me so much in understanding what the functions were doing as well as what I needed to alter to adjust the functions to fit my needs

```{r}
ggplot(frequency_dc, aes(x = proportion, y = `Children's Literature`, color = abs(`Children's Literature` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~corpus, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Children's Literature", x = NULL)
```

```{r}
cor.test(data = frequency_dc[frequency_dc$corpus == "Detective",],
         ~ proportion + `Children's Literature`)
```

## Week 3 More

```{r}
clbook_words <- childsLit_clean %>%
  unnest_tokens(word, text) %>%
  count(title, word, sort = TRUE) %>%
  ungroup()

cltotal_words <- clbook_words %>% 
  group_by(title) %>% 
  summarize(total = sum(n))

clbook_words <- left_join(clbook_words, cltotal_words)

```

```{r}
dbook_words <- detective_books %>%
  unnest_tokens(word, text) %>%
  count(title, word, sort = TRUE) %>%
  ungroup()

dtotal_words <- dbook_words %>% 
  group_by(title) %>% 
  summarize(total = sum(n))

dbook_words <- left_join(dbook_words, dtotal_words)
```

```{r}
ggplot(clbook_words, aes(n/total, fill = title)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~title, ncol = 6, scales = "free_y")
```

```{r}
ggplot(dbook_words, aes(n/total, fill = title)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~title, ncol = 5, scales = "free_y")
```

```{r}
clfreq_by_rank <- clbook_words %>% 
  group_by(title) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

clfreq_by_rank
```

```{r}
clfreq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = title)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

```{r}
rank_subset <- freq_by_rank %>% 
  filter(rank < 100,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```

```{r}
clfreq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = title)) + 
  geom_abline(intercept = -0.76, slope = -1, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```


```{r}
dfreq_by_rank <- dbook_words %>% 
  group_by(title) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

dfreq_by_rank
```


```{r}
dfreq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = title)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```


```{r}
rank_subset <- dfreq_by_rank %>% 
  filter(rank < 500,
         rank > 65)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```

```{r}
dfreq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = title)) + 
  geom_abline(intercept = -0.65, slope = -1.09, color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

```{r}
clbook_words <- clbook_words %>%
  bind_tf_idf(word, title, n)
clbook_words
```

```{r}
dbook_words <- dbook_words %>%
  bind_tf_idf(word, title, n)
dbook_words
```

```{r}
clbook_words %>%
  select(-total) %>%
  arrange(desc(tf_idf))
```

```{r}
dbook_words %>%
  select(-total) %>%
  arrange(desc(tf_idf))
```

```{r}
clbook_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(title) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~title, ncol = 6, scales = "free") +
  coord_flip()
```

```{r}
dbook_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(title) %>% 
  top_n(15) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~title, ncol = 5, scales = "free") +
  coord_flip()
```

```{r}
corpus_all <- bind_rows(child_books, detective_books)
```

```{r}
allcorpus_words <- corpus_all %>%
  unnest_tokens(word, text) %>%
  count(author, word, sort = TRUE) %>%
  ungroup()
```

```{r}
allcorpus_words
```

```{r}
plot_all <- allcorpus_words %>%
  bind_tf_idf(word, author, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  mutate(author = factor(author, levels = c("Baum, L. Frank (Lyman Frank)",
                                            "Doyle, Arthur Conan", 
                                            "Carroll, Lewis",
                                            "Milne, A. A. (Alan Alexander)")))
```

```{r}
plot_all %>% 
  group_by(author) %>% 
  top_n(15, tf_idf) %>% 
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = author)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~author, ncol = 2, scales = "free") +
  coord_flip()
```

This is my revision attempt at Week 3. 
